{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import stanza\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec_F03D_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_dataframe = pd.read_excel(r\"C:\\Users\\John\\Desktop\\Patent Datasets\\final_data\\patent_database_final_F03D.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = examples_dataframe[\"title\"].tolist()\n",
    "claims_list = examples_dataframe[\"claims\"].tolist()\n",
    "description_list = examples_dataframe[\"description\"].tolist()\n",
    "id_list = examples_dataframe[\"lens_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    # Tokenize and clean your document (implement as needed)\n",
    "    tokens = doc.lower().split()  # Replace with a more robust tokenizer\n",
    "    tokens = [t for t in tokens if t in model.wv]  # Keep only tokens in Word2Vec vocab\n",
    "    return tokens\n",
    "\n",
    "def document_vector(doc, model):\n",
    "    tokens = preprocess_document(doc)\n",
    "    if not tokens:\n",
    "        return np.zeros(model.vector_size)  # Handle empty documents\n",
    "    return np.mean([model.wv[word] for word in tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 00:10:38 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2940f4478c4dc787d1c94b64c17268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 00:10:38 INFO: Downloaded file to C:\\Users\\John\\stanza_resources\\resources.json\n",
      "2024-11-27 00:10:38 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2024-11-27 00:10:38 INFO: Using device: cuda\n",
      "2024-11-27 00:10:38 INFO: Loading: tokenize\n",
      "c:\\Users\\John\\miniconda3\\envs\\llama\\lib\\site-packages\\stanza\\models\\tokenization\\trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-27 00:10:40 INFO: Loading: mwt\n",
      "c:\\Users\\John\\miniconda3\\envs\\llama\\lib\\site-packages\\stanza\\models\\mwt\\trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-27 00:10:40 INFO: Loading: pos\n",
      "c:\\Users\\John\\miniconda3\\envs\\llama\\lib\\site-packages\\stanza\\models\\pos\\trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "c:\\Users\\John\\miniconda3\\envs\\llama\\lib\\site-packages\\stanza\\models\\common\\pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "c:\\Users\\John\\miniconda3\\envs\\llama\\lib\\site-packages\\stanza\\models\\common\\char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-27 00:10:40 INFO: Loading: lemma\n",
      "c:\\Users\\John\\miniconda3\\envs\\llama\\lib\\site-packages\\stanza\\models\\lemma\\trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-11-27 00:10:40 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma', use_gpu=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_process_example(example):\n",
    "    # Convert to lowercase\n",
    "    example = example.lower()\n",
    "    \n",
    "    # Remove punctuation and digits\n",
    "    cleaned_example = example.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "    \n",
    "    # Replace double spaces with single space\n",
    "    cleaned_example = cleaned_example.replace(\"  \", \" \")\n",
    "    \n",
    "    # Split into words and remove stop words\n",
    "    words = cleaned_example.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join filtered words back into a sentence\n",
    "    cleaned_example = ' '.join(filtered_words)\n",
    "    \n",
    "    # Stem the words\n",
    "    stemmed_sentence = [stemmer.stem(word) for word in cleaned_example.split()]\n",
    "    \n",
    "    # Lemmatize the words using Stanza\n",
    "    doc = nlp(\" \".join(stemmed_sentence))\n",
    "    lemmatized_sentence = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    \n",
    "    return ' '.join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('examples_x_lemmatized.pkl', 'rb') as file:\n",
    "    documents = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the document vector\n",
    "def document_vector(tokens, model):\n",
    "    tokens = [t for t in tokens if t in model.wv]  # Keep only tokens in Word2Vec vocab\n",
    "    if not tokens:\n",
    "        return np.zeros(model.vector_size)  # Handle empty documents\n",
    "    return np.mean([model.wv[word] for word in tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vectors = np.array([document_vector(doc, model) for doc in documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "A wind turbine comprising\n",
    "\n",
    "a wind turbine tower comprising at least two annular tower rings placed vertically on top of each other,\n",
    "\n",
    "characterized in that\n",
    "\n",
    "a first tower ring of said at least two tower rings overlaps at least a further tower ring of said at least two tower rings.\n",
    "\n",
    "2. The wind turbine according to claim 1, wherein said at least two tower rings overlaps in a substantially horizontal overlap region consisting of a bottom section of a tower ring and a top section of another tower rings.\n",
    "\n",
    "3. The wind turbine according to claim 2, wherein said substantially horizontal overlap region extends in said tower rings longitudinal direction.\n",
    "\n",
    "4. The wind turbine according to claim 2, wherein said bottom section and/or said top section are angled in an angle Î±, Î², respectively, in relation to a middle section of said tower rings.\n",
    "\n",
    "5. The wind turbine according to claim 4, wherein said angles Î±, Î² are between 0.5Â° and 15Â°, preferably 1Â° and 10Â° and most preferred between 2Â° and 7Â°.\n",
    "\n",
    "6. The wind turbine according to claim 1, wherein said at least two tower rings overlaps downwards, making an upper tower ring overlap a lower tower ring placed immediately beneath said upper tower ring and so on.\n",
    "\n",
    "7. The wind turbine according to claim 1, wherein said at least two tower rings are connected through said substantially horizontal overlap region.\n",
    "\n",
    "8. The wind turbine according to claim 7, wherein said at least two tower rings are connected by bolts.\n",
    "\n",
    "9. The wind turbine according to claim 1, wherein said at least two tower rings are of substantially constant height.\n",
    "\n",
    "10. The wind turbine according to claim 1, wherein said at least two tower rings are made of steel.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_document = clean_and_process_example(test_text)\n",
    "query_document = query_document.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = document_vector(query_document , model).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_scores = cosine_similarity(query_vector, document_vectors)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 similar documents to the query document:\n",
      "Index: 43256, Rank: 1, Score: 0.7534, Lens ID: 150-304-091-843-216, Title: A WIND TURBINE TOWER, A WIND TURBINE, A WIND TURBINE TOWER ELEVATOR AND A METHOD FOR ASSEMBLING A WIND TURBINE TOWER\n",
      "Index: 21239, Rank: 2, Score: 0.7501, Lens ID: 171-982-519-628-942, Title: TOWER OF A WIND TURBINE\n",
      "Index: 3651, Rank: 3, Score: 0.7499, Lens ID: 083-736-749-295-537, Title: WIND TURBINE TOWER, A WIND TURBINE, A WIND TURBINE TOWER ELEVATOR AND A METHOD FOR ASSEMBLING A WIND TURBINE TOWER\n",
      "Index: 20462, Rank: 4, Score: 0.7498, Lens ID: 108-619-738-940-02X, Title: TOWER OF A WIND TURBINE\n",
      "Index: 3650, Rank: 5, Score: 0.7393, Lens ID: 083-383-932-429-416, Title: A WIND TURBINE TOWER, A WIND TURBINE, A WIND TURBINE TOWER ELEVATOR AND A METHOD FOR ASSEMBLING A WIND TURBINE TOWER\n",
      "Index: 34289, Rank: 6, Score: 0.7327, Lens ID: 099-368-030-381-164, Title: Wind turbine with tensile-type structure\n",
      "Index: 565, Rank: 7, Score: 0.7074, Lens ID: 055-697-218-048-292, Title: Wind Turbine Tower, A Wind Turbine, A Wind Turbine Tower Elevator And A Method For Assembling A Wind Turbine Tower\n",
      "Index: 20225, Rank: 8, Score: 0.7072, Lens ID: 086-696-152-877-329, Title: Wind turbine tower and method of assembling\n",
      "Index: 1455, Rank: 9, Score: 0.7033, Lens ID: 130-241-190-623-496, Title: Wind turbine tower, a wind turbine, a wind turbine tower elevator and a method for assembling a wind turbine tower\n",
      "Index: 27635, Rank: 10, Score: 0.7017, Lens ID: 009-536-652-704-293, Title: CONCRETE SEGMENT OF A SECTION OF A WIND TURBINE TOWER, MOULD CONFIGURED TO CAST A CONCRETE SEGMENT AND METHOD OF ASSEMBLING A WIND TURBINE\n",
      "Index: 39303, Rank: 11, Score: 0.7013, Lens ID: 051-897-753-772-072, Title: A method for manufacturing a wind turbine blade, a wind turbine blade manufacturing facility and use thereof\n",
      "Index: 43079, Rank: 12, Score: 0.7012, Lens ID: 150-759-131-975-725, Title: A method for manufacturing a wind turbine blade, a wind turbine blade manufacturing facility and use thereof\n",
      "Index: 34101, Rank: 13, Score: 0.7011, Lens ID: 080-460-528-244-054, Title: WIND TURBINE ROTOR AND METHOD OF MOUNTING\n",
      "Index: 48331, Rank: 14, Score: 0.7008, Lens ID: 034-545-245-788-70X, Title: METHODS AND DEVICES FOR UTILIZING FLOWING POWER\n",
      "Index: 48570, Rank: 15, Score: 0.7005, Lens ID: 147-288-573-208-148, Title: A METHOD FOR MANUFACTURING A WIND TURBINE BLADE, A WIND TURBINE BLADE MANUFACTURING FACILITY, WIND TURBINE BLADES AND USES HEREOF\n",
      "Index: 48940, Rank: 16, Score: 0.7002, Lens ID: 107-205-158-921-782, Title: Methods and Devices for Utilizing Flowing Power\n",
      "Index: 40764, Rank: 17, Score: 0.6996, Lens ID: 185-256-855-292-933, Title: Method for manufacturing a wind turbine blade, a wind turbine blade manufacturing facility, wind turbine blades and uses hereof\n",
      "Index: 30384, Rank: 18, Score: 0.6989, Lens ID: 002-818-928-883-386, Title: A wind turbine tower elevator and a method for assembling a wind turbine tower\n",
      "Index: 31658, Rank: 19, Score: 0.6923, Lens ID: 115-806-629-467-795, Title: CONCRETE SEGMENT OF A SECTION OF A WIND TURBINE TOWER, MOULD CONFIGURED TO CAST A CONCRETE SEGMENT AND METHOD OF ASSEMBLING A WIND TURBINE\n",
      "Index: 32041, Rank: 20, Score: 0.6915, Lens ID: 144-910-466-074-824, Title: ASSEMBLY METHOD FOR A TELESCOPIC TOWER AND MEANS FOR IMPLEMENTING SAID METHOD\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 most similar documents\n",
    "top_indices = cosine_scores.argsort()[-20:][::-1]\n",
    "\n",
    "# Print the top 10 most similar documents\n",
    "print(\"Top 20 similar documents to the query document:\")\n",
    "for rank, idx in enumerate(top_indices, start=1):\n",
    "    score = cosine_scores[idx]\n",
    "    lens_id = examples_dataframe.iloc[idx]['lens_id']\n",
    "    title = examples_dataframe.iloc[idx]['title']\n",
    "    print(f\"Index: {idx}, Rank: {rank}, Score: {score:.4f}, Lens ID: {lens_id}, Title: {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAISS ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS index\n",
    "dimension = model.vector_size\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add document vectors to the FAISS index\n",
    "index.add(document_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = document_vector(query_document, model).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the top 10 most similar documents\n",
    "k = 20\n",
    "distances, indices = index.search(query_vector, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: 43256 (Score: 47.77791976928711) Title: A WIND TURBINE TOWER, A WIND TURBINE, A WIND TURBINE TOWER ELEVATOR AND A METHOD FOR ASSEMBLING A WIND TURBINE TOWER\n",
      "Rank 2: 3651 (Score: 48.489601135253906) Title: WIND TURBINE TOWER, A WIND TURBINE, A WIND TURBINE TOWER ELEVATOR AND A METHOD FOR ASSEMBLING A WIND TURBINE TOWER\n",
      "Rank 3: 3650 (Score: 49.92790222167969) Title: A WIND TURBINE TOWER, A WIND TURBINE, A WIND TURBINE TOWER ELEVATOR AND A METHOD FOR ASSEMBLING A WIND TURBINE TOWER\n",
      "Rank 4: 21239 (Score: 50.09141159057617) Title: TOWER OF A WIND TURBINE\n",
      "Rank 5: 20462 (Score: 50.288291931152344) Title: TOWER OF A WIND TURBINE\n",
      "Rank 6: 34289 (Score: 50.9012336730957) Title: Wind turbine with tensile-type structure\n",
      "Rank 7: 565 (Score: 54.86802673339844) Title: Wind Turbine Tower, A Wind Turbine, A Wind Turbine Tower Elevator And A Method For Assembling A Wind Turbine Tower\n",
      "Rank 8: 20225 (Score: 54.91025924682617) Title: Wind turbine tower and method of assembling\n",
      "Rank 9: 1455 (Score: 55.496273040771484) Title: Wind turbine tower, a wind turbine, a wind turbine tower elevator and a method for assembling a wind turbine tower\n",
      "Rank 10: 39303 (Score: 55.88372802734375) Title: A method for manufacturing a wind turbine blade, a wind turbine blade manufacturing facility and use thereof\n",
      "Rank 11: 43079 (Score: 55.89552688598633) Title: A method for manufacturing a wind turbine blade, a wind turbine blade manufacturing facility and use thereof\n",
      "Rank 12: 48570 (Score: 56.013389587402344) Title: A METHOD FOR MANUFACTURING A WIND TURBINE BLADE, A WIND TURBINE BLADE MANUFACTURING FACILITY, WIND TURBINE BLADES AND USES HEREOF\n",
      "Rank 13: 40764 (Score: 56.244590759277344) Title: Method for manufacturing a wind turbine blade, a wind turbine blade manufacturing facility, wind turbine blades and uses hereof\n",
      "Rank 14: 30384 (Score: 56.28268814086914) Title: A wind turbine tower elevator and a method for assembling a wind turbine tower\n",
      "Rank 15: 34101 (Score: 56.444175720214844) Title: WIND TURBINE ROTOR AND METHOD OF MOUNTING\n",
      "Rank 16: 48331 (Score: 56.84037780761719) Title: METHODS AND DEVICES FOR UTILIZING FLOWING POWER\n",
      "Rank 17: 27635 (Score: 56.88417053222656) Title: CONCRETE SEGMENT OF A SECTION OF A WIND TURBINE TOWER, MOULD CONFIGURED TO CAST A CONCRETE SEGMENT AND METHOD OF ASSEMBLING A WIND TURBINE\n",
      "Rank 18: 48940 (Score: 56.97737503051758) Title: Methods and Devices for Utilizing Flowing Power\n",
      "Rank 19: 32041 (Score: 57.437767028808594) Title: ASSEMBLY METHOD FOR A TELESCOPIC TOWER AND MEANS FOR IMPLEMENTING SAID METHOD\n",
      "Rank 20: 3192 (Score: 57.44757843017578) Title: A wind turbine tower elevator and a method for assembling a wind turbine tower\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for rank, idx in enumerate(indices[0]):\n",
    "    score = distances[0][rank]\n",
    "    print(f\"Rank {rank+1}: {idx} (Score: {distances[0][rank]}) Title: {title_list[indices[0][rank]]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
